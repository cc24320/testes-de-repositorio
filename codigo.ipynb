{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\maxim\\onedrive\\documents\\ti327v-trabalho3-equipe5\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\maxim\\onedrive\\documents\\ti327v-trabalho3-equipe5\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maxim\\onedrive\\documents\\ti327v-trabalho3-equipe5\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\maxim\\onedrive\\documents\\ti327v-trabalho3-equipe5\\.venv\\lib\\site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payers = pd.read_csv('payers-v1.csv')\n",
    "seller = pd.read_csv('seller_terminals-v1.csv')\n",
    "transactions = pd.read_csv('transactions_train-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "payers.info()\n",
    "seller.info()\n",
    "transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.rename(columns={\n",
    "    'card_id': 'CARD_ID', 'terminal_id': 'TERMINAL_ID', 'tx_amount': 'AMOUNT',\n",
    "    'tx_datetime': 'DATETIME', 'is_fraud': 'IS_FRAUD', 'transaction_id': 'TRANSACTION_ID'\n",
    "})\n",
    "transactions['DATETIME'] = pd.to_datetime(transactions['DATETIME'])\n",
    "transactions['IS_FRAUD'] = transactions['IS_FRAUD'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payers = payers.rename(columns={'card_hash': 'CARD_ID'})\n",
    "seller = seller.rename(columns={'terminal_id': 'TERMINAL_ID', 'latitude': 'LATITUDE', 'longitude': 'LONGITUDE'})\n",
    "\n",
    "df_full = transactions.merge(payers, on='CARD_ID', how='left')\n",
    "df_full = df_full.merge(seller, on='TERMINAL_ID', how='left')\n",
    "df_full = df_full.sort_values('DATETIME').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.fillna(0)\n",
    "df_full = df_full.set_index('DATETIME')\n",
    "\n",
    "GROUP_CONFIGS = [\n",
    "    ('CARD_ID', ['7D', '30D']),\n",
    "    ('TERMINAL_ID', ['1D', '7D'])\n",
    "]\n",
    "\n",
    "for GROUP_COL, TIME_WINDOWS in GROUP_CONFIGS:\n",
    "    df_grouped = df_full.groupby(GROUP_COL)\n",
    "    for window in TIME_WINDOWS:\n",
    "        tx_count_col = f'{GROUP_COL}_TX_COUNT_{window}'\n",
    "        avg_amount_col = f'{GROUP_COL}_AVG_AMOUNT_{window}'\n",
    "\n",
    "        tx_count_result = df_grouped['TRANSACTION_ID'].rolling(window=window, closed='left').count().reset_index(level=0, drop=True)\n",
    "        avg_amount_result = df_grouped['AMOUNT'].rolling(window=window, closed='left').mean().reset_index(level=0, drop=True)\n",
    "\n",
    "        df_full[tx_count_col] = tx_count_result\n",
    "        df_full[avg_amount_col] = avg_amount_result\n",
    "\n",
    "df_full = df_full.reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['TX_MONTH'] = df_full['DATETIME'].dt.to_period('M')\n",
    "all_months = sorted(df_full['TX_MONTH'].unique())\n",
    "NUM_MONTHS = len(all_months)\n",
    "\n",
    "TEST_MONTH = all_months[-1]\n",
    "VAL_MONTH = all_months[-2]\n",
    "TRAIN_MONTHS = all_months[:-2]\n",
    "\n",
    "df_train = df_full[df_full['TX_MONTH'].isin(TRAIN_MONTHS)]\n",
    "df_validation = df_full[df_full['TX_MONTH'] == VAL_MONTH]\n",
    "df_test = df_full[df_full['TX_MONTH'] == TEST_MONTH]\n",
    "\n",
    "COLS_TO_DROP = ['IS_FRAUD', 'DATETIME', 'TX_MONTH', 'TRANSACTION_ID', 'CARD_ID', 'TERMINAL_ID', 'LATITUDE', 'LONGITUDE', 'card_first_transaction', 'terminal_operation_start', 'terminal_soft_descriptor']\n",
    "features = [col for col in df_full.columns if col not in COLS_TO_DROP]\n",
    "\n",
    "X_train = df_train[features].fillna(0)\n",
    "y_train = df_train['IS_FRAUD']\n",
    "X_val = df_validation[features].fillna(0)\n",
    "y_val = df_validation['IS_FRAUD']\n",
    "X_test = df_test[features].fillna(0)\n",
    "y_test = df_test['IS_FRAUD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print('ðŸ”¹ Training model with GridSearchCV...')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('\\nâœ… Best parameter combination found:')\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "print('\\nðŸ”¹ Validation set evaluation:')\n",
    "print(f'Precision: {precision_score(y_val, y_val_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_val, y_val_pred):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_val, y_val_pred):.4f}')\n",
    "print('\\nConfusion Matrix (Validation):')\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print('\\nðŸ”¹ Test set evaluation:')\n",
    "print(f'Precision: {precision_score(y_test, y_test_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_test_pred):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_test, y_test_pred):.4f}')\n",
    "print('\\nConfusion Matrix (Test):')\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
